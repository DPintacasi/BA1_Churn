{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d29a1d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "import custom_helpers as ch\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a45b5c-51b6-4140-a5f0-defd5552ce0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "loading data...\n",
      "transforming dates...\n",
      "cast types into bool, object, categorical...\n",
      "data loaded and casted\n",
      "------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 63697 entries, 0 to 63696\n",
      "Data columns (total 43 columns):\n",
      " #   Column                             Non-Null Count  Dtype         \n",
      "---  ------                             --------------  -----         \n",
      " 0   client_id                          63697 non-null  object        \n",
      " 1   homebanking_active                 63697 non-null  bool          \n",
      " 2   has_homebanking                    63697 non-null  bool          \n",
      " 3   has_insurance_21                   63697 non-null  bool          \n",
      " 4   has_insurance_23                   63697 non-null  bool          \n",
      " 5   has_life_insurance_fixed_cap       63697 non-null  bool          \n",
      " 6   has_life_insurance_decreasing_cap  63697 non-null  bool          \n",
      " 7   has_fire_car_other_insurance       63697 non-null  bool          \n",
      " 8   has_personal_loan                  63697 non-null  bool          \n",
      " 9   has_mortgage_loan                  63697 non-null  bool          \n",
      " 10  has_current_account                63697 non-null  bool          \n",
      " 11  has_pension_saving                 63697 non-null  bool          \n",
      " 12  has_savings_account                63697 non-null  bool          \n",
      " 13  has_savings_account_starter        63697 non-null  bool          \n",
      " 14  has_current_account_starter        63697 non-null  bool          \n",
      " 15  bal_insurance_21                   63697 non-null  int64         \n",
      " 16  bal_insurance_23                   63697 non-null  int64         \n",
      " 17  cap_life_insurance_fixed_cap       63697 non-null  int64         \n",
      " 18  cap_life_insurance_decreasing_cap  63697 non-null  int64         \n",
      " 19  prem_fire_car_other_insurance      63697 non-null  int64         \n",
      " 20  bal_personal_loan                  63697 non-null  int64         \n",
      " 21  bal_mortgage_loan                  63697 non-null  int64         \n",
      " 22  bal_current_account                63697 non-null  int64         \n",
      " 23  bal_pension_saving                 63697 non-null  int64         \n",
      " 24  bal_savings_account                63697 non-null  int64         \n",
      " 25  bal_savings_account_starter        63697 non-null  int64         \n",
      " 26  bal_current_account_starter        63697 non-null  int64         \n",
      " 27  visits_distinct_so                 63697 non-null  float64       \n",
      " 28  visits_distinct_so_areas           63697 non-null  float64       \n",
      " 29  customer_since_all                 63463 non-null  datetime64[ns]\n",
      " 30  customer_since_bank                63448 non-null  datetime64[ns]\n",
      " 31  customer_gender                    63697 non-null  bool          \n",
      " 32  customer_birth_date                63697 non-null  datetime64[ns]\n",
      " 33  customer_postal_code               63697 non-null  object        \n",
      " 34  customer_occupation_code           63697 non-null  category      \n",
      " 35  customer_self_employed             63697 non-null  bool          \n",
      " 36  customer_education                 63697 non-null  category      \n",
      " 37  customer_children                  63697 non-null  category      \n",
      " 38  customer_relationship              63697 non-null  category      \n",
      " 39  target                             63697 non-null  bool          \n",
      " 40  customer_since_all_years           63463 non-null  float64       \n",
      " 41  customer_since_bank_years          63448 non-null  float64       \n",
      " 42  customer_age                       63697 non-null  int64         \n",
      "dtypes: bool(17), category(4), datetime64[ns](3), float64(4), int64(13), object(2)\n",
      "memory usage: 12.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = ch.load_data('../data/train_month_3_with_target.csv')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f222762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#non sample-dependent transformations\n",
    "def sample_agnostic_transformation(data):\n",
    "\n",
    "    # data.drop(columns = colinear_features, inplace = True)\n",
    "    \n",
    "    # num_col = data.select_dtypes(include = 'number', exclude = 'bool').columns\n",
    "    # for col in num_col:\n",
    "    #     data[col] = data[col].fillna(value = np.nan)\n",
    "    \n",
    "    # selected_col = ['client_id', 'homebanking_active', 'has_homebanking',\n",
    "    #    'has_insurance_21', 'has_insurance_23', 'has_life_insurance_fixed_cap',\n",
    "    #    'has_life_insurance_decreasing_cap', 'has_fire_car_other_insurance',\n",
    "    #    'has_personal_loan', 'has_mortgage_loan', 'has_current_account',\n",
    "    #    'has_pension_saving', 'has_savings_account',\n",
    "    #    'has_savings_account_starter', 'has_current_account_starter',\n",
    "    #    'bal_insurance_21', 'bal_insurance_23', 'cap_life_insurance_fixed_cap',\n",
    "    #    'cap_life_insurance_decreasing_cap', 'prem_fire_car_other_insurance',\n",
    "    #    'bal_personal_loan', 'bal_mortgage_loan', 'bal_current_account',\n",
    "    #    'bal_pension_saving', 'bal_savings_account',\n",
    "    #    'bal_savings_account_starter', 'bal_current_account_starter',\n",
    "    #    'visits_distinct_so', 'visits_distinct_so_areas', 'customer_since_all',\n",
    "    #    'customer_since_bank', 'customer_gender', 'customer_birth_date',\n",
    "    #    'customer_postal_code', 'customer_occupation_code',\n",
    "    #    'customer_self_employed', 'customer_education', 'customer_children',\n",
    "    #    'customer_relationship', 'target', 'customer_since_all_years',\n",
    "    #    'customer_since_bank_years', 'customer_age']\n",
    "    \n",
    "    \n",
    "    if 'target' in data.columns:\n",
    "        y = data.target\n",
    "        X = data.drop(columns = ['target'])\n",
    "        # X = X[selected_col]\n",
    "    # else:\n",
    "    #     X = data[selected_col]\n",
    "    #     y = 0\n",
    "        \n",
    "    return X, y\n",
    "\n",
    "X, y = sample_agnostic_transformation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3669c715-5668-4bfa-bcb6-6d3173272f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample dependent column specific preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42, stratify = y)\n",
    "\n",
    "\n",
    "num_col = X_train.select_dtypes(include = 'number', exclude = 'bool').columns\n",
    "cat_col = X_train.select_dtypes(include = 'category').columns\n",
    "bool_col = X_train.select_dtypes(include = 'bool').columns\n",
    "date_col = X_train.select_dtypes(include = 'datetime64').columns\n",
    "obj_col = X_train.select_dtypes(include = 'object').columns\n",
    "\n",
    "colinear_features = ['bal_insurance_23',\n",
    "     'bal_insurance_21',\n",
    "     'bal_savings_account_starter',\n",
    "     'has_homebanking',\n",
    "     'customer_since_bank_years',\n",
    "     'cap_life_insurance_decreasing_cap',\n",
    "     'has_mortgage_loan',\n",
    "     'has_fire_car_other_insurance',\n",
    "     'bal_pension_saving',\n",
    "     'bal_personal_loan']\n",
    "\n",
    "\n",
    "numeric_transformer = Pipeline(steps = [\n",
    "    ('impute',SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = OneHotEncoder(drop = 'first',handle_unknown=\"ignore\")\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('drop_ID','drop',obj_col),\n",
    "        ('drop_dates','drop',date_col),\n",
    "        ('drop_colinear', 'drop', colinear_features),\n",
    "        ('cat',categorical_transformer,cat_col),\n",
    "        ('num',numeric_transformer,num_col)\n",
    "    ],\n",
    "    remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "# f = preprocessor.fit_transform(X_train)\n",
    "# f = pd.DataFrame(f)\n",
    "# f.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "649fb9bf-4159-4ba0-9487-14f3d867f68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.062):\n",
      "{'decomp__n_components': 5, 'logistic__C': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# FIRST ROUND TEST\n",
    "\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000, tol=0.1, class_weight = 'balanced')\n",
    "# decomposer = PCA()\n",
    "decomposer = TruncatedSVD(random_state = 42)\n",
    "\n",
    "#pipeline\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"decomp\",decomposer),\n",
    "        (\"logistic\", lr)]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"decomp__n_components\": [2, 5, 10, 15, 30],\n",
    "    # \"logistic__penalty\":[\"l1\",\"l2\"],\n",
    "    \"logistic__C\": np.logspace(-4, 4, 4)\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, scoring = 'precision', n_jobs=-2)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7bbf8e0-18ce-431b-b9e9-b3df700083ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Performance Over Whole Set\n",
      "------------------------------------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Did not Churn       0.98      0.76      0.86     30892\n",
      "        Churn       0.06      0.52      0.11       957\n",
      "\n",
      "     accuracy                           0.75     31849\n",
      "    macro avg       0.52      0.64      0.48     31849\n",
      " weighted avg       0.95      0.75      0.83     31849\n",
      "\n",
      "AUC: 0.64 \n",
      "\n",
      "------------------------------------------------------------\n",
      "No. of TP (precision@250): 34\n",
      "AUC: 0.500\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# train \n",
    "\n",
    "lr = LogisticRegression(max_iter=10000, tol=0.1, class_weight = 'balanced', C = search.best_params_['logistic__C'])\n",
    "# decomposer = PCA()\n",
    "decomposer = TruncatedSVD(n_components = search.best_params_['decomp__n_components'], random_state = 42)\n",
    "\n",
    "#pipeline\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"decomp\",decomposer),\n",
    "        (\"logistic\", lr)]\n",
    ")\n",
    "\n",
    "clf = pipe.fit(X_train,y_train)\n",
    "\n",
    "# make prediction on test\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_pred_test_probs = clf.predict_proba(X_test)\n",
    "\n",
    "ch.evaluate(y_test, y_pred_test, y_pred_test_probs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "517be244-a097-4d44-934c-b411ec693599",
   "metadata": {},
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "lr_nob = LogisticRegression()\n",
    "lr = LogisticRegression(class_weight = 'balanced')\n",
    "lrcv_5 = LogisticRegressionCV(cv = 5, random_state=0, class_weight = 'balanced' )\n",
    "lrcv_10 = LogisticRegressionCV(cv = 10, random_state=0, class_weight = 'balanced')\n",
    "\n",
    "models = [lr_nob,lr,lrcv_5]\n",
    "plt.figure()\n",
    "for model in models:\n",
    "    pipe = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor),(\"classifier\", model)]\n",
    "    )\n",
    "\n",
    "    # train \n",
    "    clf = pipe.fit(X_train,y_train)\n",
    "    \n",
    "    ax = RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "    # make prediction on test\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    y_pred_test_probs = clf.predict_proba(X_test)\n",
    "    \n",
    "    print(model)\n",
    "    ch.evaluate(y_test, y_pred_test, y_pred_test_probs)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af97c8bf-f8d0-4d3b-8329-22bddf5f4e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run on submission data\n",
    "# data_sub = pd.read_csv('../data/test_month_3.csv',parse_dates = [29,30,32], index_col = 'client_id')\n",
    "# X_sub, y_sub = sample_agnostic_transformation(data_sub)\n",
    "\n",
    "# #pipeline\n",
    "# pipe = Pipeline(\n",
    "#     steps=[(\"preprocessor\", preprocessor),(\"classifier\", lrcv_5)]\n",
    "# )\n",
    "\n",
    "\n",
    "# # train \n",
    "# clf = pipe.fit(X_train,y_train)\n",
    "\n",
    "# # make prediction on test\n",
    "# y_pred_sub = clf.predict(X_sub)\n",
    "# y_pred_test_sub = clf.predict_proba(X_sub)\n",
    "# y_pred_test_sub_pos = [x[1] for x in y_pred_test_sub]\n",
    "\n",
    "# df = pd.DataFrame({'ID': X_sub.index,'PROB':y_pred_test_sub_pos})\n",
    "# today\n",
    "# df.to_csv(f'../output/lr_{today.month}{today.day}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a21a2-7d0f-4e09-95d5-0a6af0d7106f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
