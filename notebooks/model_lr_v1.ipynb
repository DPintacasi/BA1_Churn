{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d29a1d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "import custom_helpers as ch\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a45b5c-51b6-4140-a5f0-defd5552ce0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "loading data...\n",
      "transforming dates...\n",
      "cast types into bool, object, categorical...\n",
      "data loaded and casted\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df = ch.load_data('../data/train_month_3_with_target.csv')\n",
    "# print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f222762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#non sample-dependent transformations\n",
    "def sample_agnostic_transformation(data):\n",
    "\n",
    "    selected_col = [\n",
    "                'homebanking_active'\n",
    "                    # ,'has_homebanking'\n",
    "                ,'bal_mortgage_loan'\n",
    "                ,'has_life_insurance_decreasing_cap'\n",
    "                    # # ,'has_mortgage_loan'\n",
    "                ,'has_current_account'\n",
    "                    # ,'cap_life_insurance_decreasing_cap'\n",
    "                ,'bal_savings_account'\n",
    "                ,'bal_current_account'\n",
    "                ,'has_personal_loan'\n",
    "                    # ,'bal_personal_loan'\n",
    "                ,'customer_since_all_years'\n",
    "                    # ,'customer_since_bank_years'\n",
    "                ,'customer_age'\n",
    "                ,'customer_children'\n",
    "                ,'customer_education'\n",
    "                # ,'has_savings_account'\n",
    "                # ,'visits_distinct_so'\n",
    "         ]\n",
    "    \n",
    "    if 'target' in data.columns:\n",
    "        y = data.target\n",
    "        X = data.drop(columns = ['target'])\n",
    "        X = X[selected_col]\n",
    "    else:\n",
    "        X = data[selected_col]\n",
    "        y = 0\n",
    "        \n",
    "    return X, y\n",
    "\n",
    "X, y = sample_agnostic_transformation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fcef6b4-25cd-4aa8-b932-918bee44a3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample dependent column specific preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "num_col = X_train.select_dtypes(include = 'number', exclude = 'bool').columns\n",
    "cat_col = X_train.select_dtypes(include = 'category').columns\n",
    "bool_col = X_train.select_dtypes(include = 'bool').columns\n",
    "date_col = X_train.select_dtypes(include = 'datetime64').columns\n",
    "obj_col = X_train.select_dtypes(include = 'object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9f0284e-1a28-4101-85c2-bb9522489526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer, KBinsDiscretizer\n",
    "\n",
    "numeric_transformer = Pipeline(steps = [\n",
    "    ('impute',SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = OneHotEncoder(drop = 'first',handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('drop_ID','drop',obj_col),\n",
    "        ('drop_dates','drop',date_col),\n",
    "        ('cat',categorical_transformer,cat_col),\n",
    "        ('num',numeric_transformer,num_col)\n",
    "    ],\n",
    "    remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "f = preprocessor.fit_transform(X_train)\n",
    "f = pd.DataFrame(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b1f11f4-e57b-47b1-8c9e-752830834722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(class_weight='balanced')\n",
      "------------------------------------------------------------\n",
      "Performance Over Whole Set\n",
      "------------------------------------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Did not Churn       0.98      0.68      0.81     30889\n",
      "        Churn       0.06      0.66      0.11       960\n",
      "\n",
      "     accuracy                           0.68     31849\n",
      "    macro avg       0.52      0.67      0.46     31849\n",
      " weighted avg       0.96      0.68      0.79     31849\n",
      "\n",
      "------------------------------------------------------------\n",
      "AUC: 0.67\n",
      "No. of TP (precision@250): 39\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "LogisticRegressionCV(class_weight='balanced', cv=5, random_state=0)\n",
      "------------------------------------------------------------\n",
      "Performance Over Whole Set\n",
      "------------------------------------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Did not Churn       0.98      0.70      0.82     30889\n",
      "        Churn       0.06      0.57      0.10       960\n",
      "\n",
      "     accuracy                           0.70     31849\n",
      "    macro avg       0.52      0.64      0.46     31849\n",
      " weighted avg       0.95      0.70      0.80     31849\n",
      "\n",
      "------------------------------------------------------------\n",
      "AUC: 0.64\n",
      "No. of TP (precision@250): 38\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "LogisticRegressionCV(class_weight='balanced', cv=10, random_state=0)\n",
      "------------------------------------------------------------\n",
      "Performance Over Whole Set\n",
      "------------------------------------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Did not Churn       0.98      0.70      0.82     30889\n",
      "        Churn       0.06      0.57      0.10       960\n",
      "\n",
      "     accuracy                           0.70     31849\n",
      "    macro avg       0.52      0.64      0.46     31849\n",
      " weighted avg       0.95      0.70      0.80     31849\n",
      "\n",
      "------------------------------------------------------------\n",
      "AUC: 0.64\n",
      "No. of TP (precision@250): 38\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "models = [LogisticRegression(class_weight = 'balanced')\n",
    "          ,LogisticRegressionCV(cv = 5, random_state=0, class_weight = 'balanced' )\n",
    "          ,LogisticRegressionCV(cv = 10, random_state=0, class_weight = 'balanced')\n",
    "         ]\n",
    "\n",
    "plt.figure()\n",
    "for model in models:\n",
    "    pipe = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor),(\"classifier\", model)]\n",
    "    )\n",
    "\n",
    "    # train \n",
    "    clf = pipe.fit(X_train,y_train)\n",
    "    \n",
    "    # make prediction on test\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    y_pred_test_probs = clf.predict_proba(X_test)\n",
    "    \n",
    "    print(model)\n",
    "    ch.evaluate(y_test, y_pred_test, y_pred_test_probs)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3506b1d3-9209-4486-8fbc-18f3e5aef2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logistic__C': array([1.00000000e-10, 2.78255940e-09, 7.74263683e-08, 2.15443469e-06,\n",
      "       5.99484250e-05, 1.66810054e-03, 4.64158883e-02, 1.29154967e+00,\n",
      "       3.59381366e+01, 1.00000000e+03])}\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegressionCV(max_iter=10000, tol=0.5, class_weight = 'balanced')\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"logistic\", lr)]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "        \"logistic__C\": np.logspace(-10,3,10)\n",
    "    }\n",
    "\n",
    "print(param_grid)\n",
    "\n",
    "gridscorer = ch.gridscorer() # customer scorer (precision@250)\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, scoring = gridscorer, n_jobs=-2)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n",
    "\n",
    "clf = search.best_estimator_.fit(X_train,y_train)\n",
    "\n",
    "# make prediction on test\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_pred_test_probs = clf.predict_proba(X_test)\n",
    "\n",
    "ch.evaluate(y_test, y_pred_test, y_pred_test_probs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f675362-3a41-4922-a7df-508e715f30bb",
   "metadata": {},
   "source": [
    "# run on submission data\n",
    "data_sub = ch.load_data('../data/test_month_3.csv')\n",
    "X_sub, y_sub = sample_agnostic_transformation(data_sub)\n",
    "\n",
    "# make prediction on test\n",
    "y_pred_sub = clf.predict(X_sub)\n",
    "y_pred_test_sub = clf.predict_proba(X_sub)\n",
    "y_pred_test_sub_pos = [x[1] for x in y_pred_test_sub]\n",
    "\n",
    "df = pd.DataFrame({'ID': data_sub.client_id,'PROB':y_pred_test_sub_pos})\n",
    "today = dt.datetime.today()\n",
    "df.to_csv(f'../output/lr_{today.month}{today.day}2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9deb29e-5304-4275-87f6-1c9c041b3c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
